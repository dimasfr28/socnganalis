<div align="center">

# SOC-NGANALIS: Social Insight & Analytics

### *Analisis Cerdas untuk Media Sosial Twitter/X dengan AI & Machine Learning*

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-009688.svg)](https://fastapi.tiangolo.com/)
[![Django](https://img.shields.io/badge/Django-4.2+-092E20.svg)](https://www.djangoproject.com/)
[![Docker](https://img.shields.io/badge/Docker-Ready-2496ED.svg)](https://www.docker.com/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-316192.svg)](https://www.postgresql.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

[Fitur](#-fitur-utama) â€¢ [Demo](#-screenshot) â€¢ [Instalasi](#-quick-start) â€¢ [Dokumentasi](#-dokumentasi) â€¢ [API](#-api-reference)

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" width="100%">

</div>

## ğŸ“– Tentang Proyek

Platform analytics all-in-one yang menggabungkan **scraping Twitter/X**, **analisis sentimen AI**, **clustering machine learning**, dan **visualisasi interaktif** untuk membantu Anda memahami performa media sosial secara mendalam.

### ğŸ¯ Kenapa Platform Ini?

- âœ… **Multi-Dataset Management** - Upload dan kelola berbagai dataset tanpa overwrite
- âœ… **AI-Powered Sentiment Analysis** - Analisis sentimen menggunakan LinearSVM & TF-IDF
- âœ… **Smart Twitter Scraper** - Scrape replies dengan dynamic limit berdasarkan engagement
- âœ… **Topic Modeling** - Identifikasi topik dan pilar konten secara otomatis
- âœ… **Peak Hours Detection** - Temukan jam terbaik untuk posting menggunakan DBSCAN clustering
- âœ… **Interactive Dashboard** - Visualisasi real-time dengan Chart.js
- âœ… **Dockerized** - Deploy dengan satu command

---

## âœ¨ Fitur Utama

### ğŸ¨ 1. Descriptive Analytics
<table>
<tr>
<td width="50%">

#### ğŸ“Š Statistics Cards
- Total Posts, Comments, Mentions, Retweets
- Engagement Rate Calculator
- Growth Metrics

#### ğŸ“ˆ Engagement Analysis
- **Pie Chart**: Engagement by Post Type
- **Bar Chart**: Top Hashtags (Top 10)
- **Line Chart**: Engagement by Day of Week
- **Time Series**: Daily activity trends

</td>
<td width="50%">

#### â° Peak Activity Hours
- **DBSCAN Clustering** untuk identifikasi pola
- **PCA Visualization** untuk clustering
- Rekomendasi jam posting optimal
- Heatmap activity per jam

#### ğŸ” Deep Dive Analysis
- Post performance breakdown
- Engagement rate per post type
- User interaction patterns

</td>
</tr>
</table>

---

### ğŸ§  2. Sentiment Analysis (AI-Powered)

```
ğŸ¤– Machine Learning Model: LinearSVM + TF-IDF Vectorizer
ğŸ“Š Classification: Positive, Negative, Neutral
ğŸ¯ Accuracy: Trained on Indonesian social media corpus
```

**Fitur:**
- Real-time sentiment prediction untuk setiap reply/comment
- Sentiment distribution pie chart
- Word cloud untuk positive/negative words
- Sentiment timeline analysis
- Export sentiment report

---

### ğŸ·ï¸ 3. Topic & Pillar Analysis

Identifikasi topik utama dalam diskusi:
- **Topic Extraction** menggunakan NLP
- **Content Pillar Categorization**
- **Hashtag Clustering**
- **Keyword Frequency Analysis**
- Topic trend over time

---

### ğŸ˜Š 4. Emotion Analysis

Klasifikasi emosi lebih detail:
- ğŸ˜Š Joy (Senang)
- ğŸ˜¢ Sadness (Sedih)
- ğŸ˜  Anger (Marah)
- ğŸ˜¨ Fear (Takut)
- ğŸ˜® Surprise (Terkejut)

---

### ğŸ’¡ 5. Smart Recommendations

AI-generated recommendations berdasarkan data:
- ğŸ¯ Best time to post
- ğŸ“ Content type recommendations
- #ï¸âƒ£ Hashtag suggestions
- ğŸ“Š Engagement optimization tips

---

### ğŸ—‚ï¸ 6. Dataset Manager

**NEW!** Multi-dataset management system:
- Upload dataset baru (tweet.xlsx + replies.csv)
- Switch antara dataset dengan satu klik
- Base dataset tetap aman (immutable)
- View stats per dataset
- Delete dataset yang tidak digunakan

---

## ğŸ—ï¸ Arsitektur

```mermaid
graph LR
    A[Twitter/X] -->|Scraping| B[tweet-harvest]
    B --> C[tweets-data/]
    C --> D[FastAPI Backend]
    D --> E[PostgreSQL]
    D --> F[Django Frontend]
    F --> G[User Browser]
    H[ML Models] --> D
    I[DBSCAN/PCA] --> D
```

### ğŸ› ï¸ Tech Stack

<table>
<tr>
<td>

**Backend**
- FastAPI (Analytics API)
- Django (Web Server)
- PostgreSQL (Database)
- Uvicorn (ASGI Server)

</td>
<td>

**Data Science**
- Pandas (Data Processing)
- Scikit-learn (ML Models)
- DBSCAN (Clustering)
- PCA (Dimensionality Reduction)
- TF-IDF (Text Vectorization)

</td>
<td>

**Frontend**
- HTML5/CSS3/JavaScript
- Chart.js (Visualization)
- Responsive Design
- Modern UI/UX

</td>
<td>

**Infrastructure**
- Docker & Docker Compose
- Node.js (Scraping Tools)
- tweet-harvest (Data Collection)

</td>
</tr>
</table>

---

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

```bash
âœ… Docker & Docker Compose
âœ… Node.js 16+ (untuk scraping standalone)
âœ… Python 3.10+ (untuk scraping standalone)
âœ… Twitter/X Auth Token (untuk scraping)
```

### âš¡ Instalasi & Menjalankan

#### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/yourusername/crawling_sosmed.git
cd crawling_sosmed
```

#### 2ï¸âƒ£ Setup Environment Variables

```bash
# Copy .env template
cp .env.example .env

# Edit .env dan tambahkan Twitter Auth Token
nano .env
```

```env
# Twitter Authentication
TWITTER_AUTH_TOKEN=your_twitter_auth_token_here

# Data Paths
DATA_PATH=/home/dimas/crawling_sosmed/tweets-data

# Model Paths
MODEL_PATH=/home/dimas/crawling_sosmed/assets/model/LinearSVM.pkl
VECTORIZER_PATH=/home/dimas/crawling_sosmed/assets/model/tfidf_vectorizer.pkl
```

#### 3ï¸âƒ£ Jalankan dengan Docker

```bash
# Build dan start semua services
docker compose up --build

# Atau run di background
docker compose up -d --build
```

#### 4ï¸âƒ£ Akses Aplikasi

ğŸŒ **URLs:**
- ğŸ  **Django (Frontend)**: http://localhost:8000
- âš¡ **FastAPI (API)**: http://localhost:8001
- ğŸ“š **API Docs (Swagger)**: http://localhost:8001/docs
- ğŸ—„ï¸ **PostgreSQL**: localhost:5433

---

## ğŸ“± Panduan Penggunaan

### ğŸ” 1. Scraping Data Twitter

#### **Option A: Docker (Recommended)**

```bash
# Masuk ke FastAPI container
docker compose exec fastapi bash

# Jalankan scraper
python tweet_scraper.py
```

#### **Option B: Standalone Script**

```bash
# Set Twitter token
export TWITTER_AUTH_TOKEN="your_token_here"

# Jalankan script wrapper (auto-check dependencies)
./run_scraper.sh

# Atau langsung
python3 get_Data.py
```

ğŸ“– **Dokumentasi Scraping:**
- [QUICK_START.md](QUICK_START.md) - Panduan cepat scraping
- [SCRAPER_README.md](SCRAPER_README.md) - Dokumentasi lengkap

### ğŸ“Š 2. Upload & Manage Dataset

1. Buka **Dataset Manager**: http://localhost:8000/dataset-manager/
2. Klik **"Upload New Dataset"**
3. Pilih files:
   - `tweet.xlsx` (Header di baris ke-5)
   - `replies.csv` (Hasil scraping)
4. Klik **"Gunakan"** untuk switch dataset
5. Lihat analytics dengan dataset aktif

### ğŸ“ˆ 3. View Analytics

Navigasi ke halaman analytics:
- **Descriptive**: http://localhost:8000/analytics/
- **Sentiment**: http://localhost:8000/sentiment/
- **Topic & Pillar**: http://localhost:8000/topic-pillar/
- **Emotion**: http://localhost:8000/emotion/
- **Recommendations**: http://localhost:8000/recommendations/

---

## ğŸ”Œ API Reference

### ğŸ“¡ FastAPI Endpoints

#### **Data Management**

```http
GET  /api/data-status                 # Check data availability & stats
POST /api/upload-dataset               # Upload new dataset (multipart/form-data)
POST /api/select-dataset/{name}        # Switch active dataset
GET  /api/list-datasets                # List all datasets
DELETE /api/delete-dataset/{name}      # Delete dataset
```

#### **Analytics**

```http
GET /api/basic-stats                   # Basic statistics
GET /api/engagement-by-type            # Engagement by post type
GET /api/peak-hours                    # Peak activity hours (DBSCAN)
GET /api/hashtags                      # Top hashtags
GET /api/engagement-by-day             # Engagement by day of week
GET /api/clustering-pca                # PCA clustering visualization
```

#### **Sentiment & Emotion**

```http
GET /api/sentiment-distribution        # Sentiment analysis results
GET /api/emotion-analysis              # Emotion classification
GET /api/sentiment-timeline            # Sentiment over time
```

#### **Topic Analysis**

```http
GET /api/topic-pillars                 # Topic & pillar analysis
GET /api/keyword-frequency             # Keyword frequency analysis
```

#### **Recommendations**

```http
GET /api/recommendations               # AI-generated recommendations
```

### ğŸ“ Example Request

```bash
# Upload new dataset
curl -X POST "http://localhost:8001/api/upload-dataset" \
  -F "dataset_name=indihome_jan2025" \
  -F "tweet_file=@tweet.xlsx" \
  -F "replies_file=@replies.csv"

# Switch to dataset
curl -X POST "http://localhost:8001/api/select-dataset/indihome_jan2025"

# Get analytics
curl "http://localhost:8001/api/basic-stats"
```

---

## ğŸ“‚ Struktur Project

```
crawling_sosmed/
â”œâ”€â”€ ğŸ“„ docker-compose.yml              # Docker orchestration
â”œâ”€â”€ ğŸ“„ .env                            # Environment variables
â”œâ”€â”€ ğŸ“œ README.md                       # This file
â”œâ”€â”€ ğŸ“œ QUICK_START.md                  # Quick scraping guide
â”œâ”€â”€ ğŸ“œ SCRAPER_README.md               # Full scraping docs
â”œâ”€â”€ ğŸ run_scraper.sh                  # Scraper wrapper script
â”‚
â”œâ”€â”€ ğŸ“ django_app/                     # Django Frontend
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â”œâ”€â”€ ğŸ“„ manage.py
â”‚   â”œâ”€â”€ ğŸ“ webapp/                     # Project config
â”‚   â”‚   â”œâ”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ wsgi.py
â”‚   â””â”€â”€ ğŸ“ analytics/                  # Main app
â”‚       â”œâ”€â”€ views.py                   # View controllers
â”‚       â”œâ”€â”€ urls.py                    # URL routing
â”‚       â”œâ”€â”€ models.py                  # Database models
â”‚       â”œâ”€â”€ ğŸ“ templates/              # HTML templates
â”‚       â”‚   â”œâ”€â”€ base.html
â”‚       â”‚   â”œâ”€â”€ home.html
â”‚       â”‚   â”œâ”€â”€ descriptive_analytics.html
â”‚       â”‚   â”œâ”€â”€ sentiment_analysis.html
â”‚       â”‚   â”œâ”€â”€ topic_pillar.html
â”‚       â”‚   â”œâ”€â”€ emotion_analysis.html
â”‚       â”‚   â”œâ”€â”€ recommendations.html
â”‚       â”‚   â””â”€â”€ dataset_manager.html   # ğŸ†• Dataset manager
â”‚       â””â”€â”€ ğŸ“ static/
â”‚           â”œâ”€â”€ css/
â”‚           â””â”€â”€ js/
â”‚
â”œâ”€â”€ ğŸ“ fastapi_app/                    # FastAPI Backend
â”‚   â”œâ”€â”€ ğŸ“„ Dockerfile
â”‚   â”œâ”€â”€ ğŸ main.py                     # Main API application
â”‚   â”œâ”€â”€ ğŸ data_processor.py           # Data processing utilities
â”‚   â”œâ”€â”€ ğŸ sentiment_analyzer.py       # Sentiment analysis
â”‚   â”œâ”€â”€ ğŸ topic_pillar_processor.py   # Topic extraction
â”‚   â”œâ”€â”€ ğŸ emotion_classifier.py       # Emotion classification
â”‚   â””â”€â”€ ğŸ tweet_scraper.py            # Twitter scraper wrapper
â”‚
â”œâ”€â”€ ğŸ“ tweets-data/                    # Data directory
â”‚   â”œâ”€â”€ ğŸ“„ tweet.xlsx                  # Main tweet data (default)
â”‚   â”œâ”€â”€ ğŸ“„ replies.csv                 # All replies (default)
â”‚   â””â”€â”€ ğŸ“ datasets/                   # ğŸ†• Multiple datasets
â”‚       â”œâ”€â”€ indihome/
â”‚       â”‚   â”œâ”€â”€ tweet.xlsx
â”‚       â”‚   â””â”€â”€ replies.csv
â”‚       â””â”€â”€ telkomsel/
â”‚           â”œâ”€â”€ tweet.xlsx
â”‚           â””â”€â”€ replies.csv
â”‚
â”œâ”€â”€ ğŸ“ assets/                         # ML Models & Resources
â”‚   â””â”€â”€ ğŸ“ model/
â”‚       â”œâ”€â”€ LinearSVM.pkl              # Sentiment model
â”‚       â””â”€â”€ tfidf_vectorizer.pkl       # Text vectorizer
â”‚
â””â”€â”€ ğŸ“ get_data/                       # Scraping utilities
    â””â”€â”€ ğŸ replies.py                  # Reply scraping logic
```

---

## ğŸ§ª Data Format

### ğŸ“Š tweet.xlsx (Input)

Header dimulai di **baris ke-5** (row 5), format:

| Name | Type | Caption | Date | Likes | Replies | Retweets | Permalink |
|------|------|---------|------|-------|---------|----------|-----------|
| indihome | Photo | Ini caption... | 2025-11-15T19:51:55+07:00 | 150 | 45 | 30 | https://twitter.com/indihome/status/123... |

**Kolom yang digunakan:**
- `Name` - Account name
- `Type` - Post type (Photo, Video, Link, Animated_gif, Status)
- `Caption` - Post content (untuk hashtag extraction)
- `Date` - ISO timestamp
- `Likes`, `Replies`, `Retweets` - Engagement metrics
- `Permalink` - Tweet URL (untuk extract tweet ID)

### ğŸ“„ replies.csv (Output)

Format hasil scraping menggunakan tweet-harvest:

| id | conversation_id | created_at | user_id | username | text | ... |
|----|----------------|------------|---------|----------|------|-----|
| 1234... | 5678... | Sat Nov 15 23:59:58 +0000 2025 | 9876... | johndoe | Great service! | ... |

**Kolom tambahan:**
- `reply_to_tweet_id` - ID tweet yang di-reply (ditambahkan oleh scraper)
- `sentiment` - Sentimen analysis result (ditambahkan oleh ML model)
- `emotion` - Emotion classification (ditambahkan oleh ML model)

---

## ğŸ¤– Machine Learning Models

### 1. Sentiment Analysis: LinearSVM

```python
Model: LinearSVM (Scikit-learn)
Vectorizer: TF-IDF
Training Data: Indonesian social media corpus
Classes: ['Positive', 'Negative', 'Neutral']
Preprocessing: Lowercase, remove URLs, mentions, hashtags
```

**Performance:**
- âœ… Optimized for Indonesian language
- âœ… Handles informal text & slang
- âœ… Real-time inference (<10ms per text)

### 2. Clustering: DBSCAN

```python
Algorithm: DBSCAN (Density-Based Spatial Clustering)
Use Case: Peak hours detection
Parameters: eps=0.5, min_samples=5
Features: Hour of day (0-23)
```

**Output:**
- Cluster labels untuk setiap jam
- Optimal posting hours
- Activity patterns

### 3. Dimensionality Reduction: PCA

```python
Algorithm: PCA (Principal Component Analysis)
Use Case: Clustering visualization
Components: 2D projection
```

---

## ğŸ³ Docker Configuration

### Services

#### ğŸ—„ï¸ PostgreSQL Database
```yaml
Port: 5433 (host) â†’ 5432 (container)
Database: socialdb
User: socialuser
Volume: postgres_data (persistent)
```

#### ğŸŒ Django Frontend
```yaml
Port: 8000
Volumes:
  - ./django_app:/app
  - ./tweets-data:/home/dimas/crawling_sosmed/tweets-data
```

#### âš¡ FastAPI Backend
```yaml
Port: 8001
Volumes:
  - ./fastapi_app:/app
  - ./tweets-data:/home/dimas/crawling_sosmed/tweets-data
  - ./assets:/home/dimas/crawling_sosmed/assets
Memory: 2GB limit, 512MB reserved
Hot Reload: Enabled
```

### Useful Commands

```bash
# Start services
docker compose up -d

# View logs
docker compose logs -f

# Restart specific service
docker compose restart fastapi

# Enter container
docker compose exec fastapi bash
docker compose exec django bash

# Stop all
docker compose down

# Remove volumes (âš ï¸ deletes data)
docker compose down -v

# Rebuild after code changes
docker compose up --build
```

---

## ğŸ”§ Troubleshooting

### âŒ Port Already in Use

```bash
# Check what's using port
sudo lsof -i :8000
sudo lsof -i :8001
sudo lsof -i :5433

# Stop services
docker compose down
```

### âŒ Missing Python Dependencies (Standalone Script)

```bash
# Install for Python 3.10
python3.10 -m pip install pandas openpyxl

# Or use pip3
pip3 install pandas openpyxl
```

### âŒ Node.js Not Found (Scraping)

```bash
# Ubuntu/Debian
sudo apt-get install nodejs npm

# Verify
node --version
npm --version
```

### âŒ Twitter Auth Token Invalid

1. Buka https://twitter.com atau https://x.com
2. Login ke akun Anda
3. Tekan **F12** â†’ Tab **Application**
4. **Cookies** â†’ pilih `https://twitter.com`
5. Copy cookie `auth_token`
6. Update `.env` atau environment variable

### âŒ No Data Showing in Dashboard

```bash
# Check active dataset
curl http://localhost:8001/api/data-status

# Switch to correct dataset
curl -X POST http://localhost:8001/api/select-dataset/indihome

# Verify files exist
ls -lh tweets-data/
ls -lh tweets-data/datasets/
```

### âŒ FastAPI Container Crashes

```bash
# Check logs
docker compose logs fastapi

# Common issues:
# 1. Missing python-multipart (should be in Dockerfile)
# 2. Memory limit (adjust in docker-compose.yml)
# 3. Model files missing (check assets/model/)

# Rebuild
docker compose build fastapi
docker compose up -d fastapi
```

---

## ğŸ“ Dokumentasi Tambahan

- ğŸ“˜ [QUICK_START.md](QUICK_START.md) - Panduan cepat untuk scraping Twitter
- ğŸ“— [SCRAPER_README.md](SCRAPER_README.md) - Dokumentasi lengkap scraper
- ğŸ“™ [DOKUMENTASI_APLIKASI.md](DOKUMENTASI_APLIKASI.md) - Dokumentasi teknis aplikasi
- ğŸ“• [FEATURE_POST_MODAL.md](FEATURE_POST_MODAL.md) - Fitur post detail modal

---

## ğŸ›£ï¸ Roadmap

### ğŸ¯ Coming Soon

- [ ] **Real-time Monitoring** - WebSocket untuk live updates
- [ ] **Export Reports** - PDF/Excel export dengan branding
- [ ] **Advanced Filters** - Date range, account, sentiment filters
- [ ] **User Authentication** - Login & role-based access
- [ ] **Multi-Platform** - Support Instagram, Facebook, LinkedIn
- [ ] **Automated Scheduling** - Cron jobs untuk periodic scraping
- [ ] **Email Alerts** - Notifikasi untuk sentiment spike/drop
- [ ] **Comparison Mode** - Compare multiple datasets side-by-side
- [ ] **API Rate Limiting** - Redis-based rate limiter
- [ ] **Dark Mode** - Dark theme untuk dashboard

### ğŸš€ Future Enhancements

- **NLP Improvements**
  - Named Entity Recognition (NER)
  - Aspect-Based Sentiment Analysis
  - Sarcasm Detection
  - Multilingual Support

- **Advanced Analytics**
  - Influencer Detection
  - Trend Forecasting
  - Viral Content Prediction
  - Community Detection

- **Infrastructure**
  - Kubernetes deployment
  - CI/CD pipeline
  - Auto-scaling
  - Monitoring (Prometheus/Grafana)

---

## ğŸ¤ Contributing

Kontribusi sangat diterima! Silakan:

1. Fork repository ini
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open Pull Request

### ğŸ“ Contribution Guidelines

- Gunakan meaningful commit messages
- Update dokumentasi jika ada perubahan API
- Tambahkan unit tests untuk fitur baru
- Follow PEP 8 (Python) dan ESLint (JavaScript)

---

## ğŸ“„ License

Distributed under the MIT License. See `LICENSE` for more information.

---

## ğŸ‘¨â€ğŸ’» Author

**Dimas**

- GitHub: [@yourusername](https://github.com/yourusername)
- Email: your.email@example.com

---

## ğŸ™ Acknowledgments

- [tweet-harvest](https://github.com/th3c0d3br34ker/tweet-harvest) - Twitter scraping tool
- [FastAPI](https://fastapi.tiangolo.com/) - Modern Python web framework
- [Django](https://www.djangoproject.com/) - High-level Python web framework
- [Chart.js](https://www.chartjs.org/) - Beautiful charts library
- [Scikit-learn](https://scikit-learn.org/) - Machine learning library

---

<div align="center">

### â­ Star this repo if you find it helpful!

Made with â¤ï¸ by Dimas

<img src="https://raw.githubusercontent.com/andreasbm/readme/master/assets/lines/rainbow.png" width="100%">

**[â¬† Back to Top](#-social-media-analytics-platform)**

</div>
